{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load processed single hashtag tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('df_processed_single_hashtag.pickle', 'rb')\n",
    "df = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained classifiers and vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('Clinton_logistic_classifier.pickle', 'rb')\n",
    "C_logistic_classifier = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('Clinton_vectorizer.pickle', 'rb')\n",
    "C_vectorizer = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('Trump_logistic_classifier.pickle', 'rb')\n",
    "T_logistic_classifier = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('Trump_vectorizer.pickle', 'rb')\n",
    "T_vectorizer = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get list of hashtags and counts from single hashtag tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtag_multiplicites = df['hashtags'].value_counts()\n",
    "hashtag_multiplicites.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#only take hashtags which are the unique take on more than 50 tweets\n",
    "hashtag_multiplicites = hashtag_multiplicites[hashtag_multiplicites>=50]\n",
    "Usable_hashtag_list = hashtag_multiplicites.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolate the single subject tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    if word in text.split():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns 1 if at least one of the words in the list is in the text and 0 otherwise\n",
    "def list_words(words,text):\n",
    "    ind = 0\n",
    "    for item in words:\n",
    "        if word_in_text(item,text) == True:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hillary_names = ['clinton','hillari','she','her']#'hilari' is how all versions of 'hillary' appear after text processing\n",
    "Trump_names = ['trump','donald','he','his']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find the tweets which have only one subject\n",
    "df['Clinton_names'] = df['processed_text'].apply(lambda tweet: list_words(Hillary_names,tweet))\n",
    "df['Trump_names'] = df['processed_text'].apply(lambda tweet: list_words(Trump_names,tweet))\n",
    "df['#_of_names'] = df['Clinton_names'] + df['Trump_names']\n",
    "df = df[df['#_of_names'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#separate by subject\n",
    "Clinton_focused_tweets = df[df['Clinton_names']==1][['processed_text','hashtags']]\n",
    "Trump_focused_tweets = df[df['Trump_names']==1][['processed_text','hashtags']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dictionaries for Clinton_focused and Trump_focused\n",
    "# keys are hashtags, values list of tweet text for that hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For Clinton_focused_tweets\n",
    "C = {}\n",
    "for hashtag in Usable_hashtag_list:\n",
    "    C[hashtag] = Clinton_focused_tweets[Clinton_focused_tweets['hashtags'] == hashtag]['processed_text'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For Trump_focused_tweets\n",
    "T = {}\n",
    "for hashtag in Usable_hashtag_list:\n",
    "    T[hashtag] = Trump_focused_tweets[Trump_focused_tweets['hashtags'] == hashtag]['processed_text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify hashtags probabilistically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dictionaries for the probability each hashtag is for clinton and trump respectively\n",
    "Clinton_prob = {}\n",
    "Trump_prob = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for hashtag in Usable_hashtag_list:\n",
    "    try:\n",
    "        C_count_A = 0\n",
    "        for C_tweet in C[hashtag]:\n",
    "            if C_logistic_classifier.predict_proba(C_vectorizer.transform([C_tweet]))[0][1] > .5:\n",
    "                C_count_A = C_count_A + 1\n",
    "\n",
    "        C_count_B = 0\n",
    "        for T_tweet in T[hashtag]:\n",
    "            if T_logistic_classifier.predict_proba(T_vectorizer.transform([T_tweet]))[0][0] > .5:\n",
    "                C_count_B = C_count_B + 1\n",
    "    \n",
    "   \n",
    "        C_prob = float(C_count_A+C_count_B)/(len(C[hashtag])+len(T[hashtag]))\n",
    "        T_prob = 1-C_prob\n",
    "        Clinton_prob[hashtag] = C_prob\n",
    "        Trump_prob[hashtag] = T_prob\n",
    "    except:\n",
    "        print hashtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Export hashtag prob classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('Clinton_hashtag_prob.pickle', 'wb')\n",
    "pickle.dump(Clinton_prob, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('Trump_hashtag_prob.pickle', 'wb')\n",
    "pickle.dump(Trump_prob, f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
