{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.classify.scikitlearn import SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import cross_validation\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load processed single hashtag tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('df_processed_single_hashtag.pickle', 'rb')\n",
    "df = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop two training/testing sets for text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name search functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    if word in text.split():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns 1 if at least one of the words in the list is in the text and 0 otherwise\n",
    "def list_words(words,text):\n",
    "    ind = 0\n",
    "    for item in words:\n",
    "        if word_in_text(item,text) == True:\n",
    "            return 1\n",
    "    return 0       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hillary_names = ['clinton','hilari','she','her']#'hilari' is how all versions of 'hillary' appear after text processing\n",
    "Trump_names = ['trump','donald','he','his']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilize main campaign driven hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### #ImWithHer tweets separated into pro-Clinton and anti-Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "For_Hillary_df = pd.DataFrame()\n",
    "For_Hillary_df['text'] = df[(df['hashtags'] == 'imwithher')]['processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "For_Hillary_df['pos_hillary'] = For_Hillary_df['text'].apply(lambda tweet: list_words(Hillary_names,tweet))\n",
    "For_Hillary_df['neg_trump'] = For_Hillary_df['text'].apply(lambda tweet: list_words(Trump_names,tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isolate single subject tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take those with Hillary's names and not Trump's names\n",
    "Pos_Hillary_text = For_Hillary_df[(For_Hillary_df['pos_hillary'] == 1) & (For_Hillary_df['neg_trump'] == 0)]['text']\n",
    "#take those with Trump's names and not Hillary's names\n",
    "Neg_Trump_text = For_Hillary_df[(For_Hillary_df['pos_hillary'] == 0) & (For_Hillary_df['neg_trump'] == 1)]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### #MakeAmericaGreatAgain tweets separated into pro-Trump and anti-Clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "For_Donald_df = pd.DataFrame()\n",
    "For_Donald_df['text'] = df[(df['hashtags'] == 'makeamericagreatagain') | (df['hashtags'] == 'maga')]['processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "For_Donald_df['pos_trump'] = For_Donald_df['text'].apply(lambda tweet: list_words(Trump_names,tweet))\n",
    "For_Donald_df['neg_hillary'] = For_Donald_df['text'].apply(lambda tweet: list_words(Hillary_names,tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isolate single subject tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take those with Trump's names and not Hillary's names\n",
    "Pos_Trump_text = For_Donald_df[(For_Donald_df['pos_trump'] == 1) & (For_Donald_df['neg_hillary'] == 0)]['text']\n",
    "#take those with Hillary's names and not Trump's names, there are 1112 of them\n",
    "Neg_Hillary_text = For_Donald_df[(For_Donald_df['pos_trump'] == 0) & (For_Donald_df['neg_hillary'] == 1)]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rand_Pos_Hillary = [X.lower() for X in Pos_Hillary_text.tolist()]\n",
    "random.shuffle(Rand_Pos_Hillary)\n",
    "\n",
    "Rand_Neg_Hillary = [X.lower() for X in Neg_Hillary_text.tolist()]\n",
    "random.shuffle(Rand_Neg_Hillary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#80% training, 20% tesitng\n",
    "Clinton_X_train = Rand_Pos_Hillary[:int(.8*Hillary_length)] + Rand_Neg_Hillary[:int(.8*Hillary_length)]\n",
    "Clinton_X_test = Rand_Pos_Hillary[int(.8*Hillary_length):] + Rand_Neg_Hillary[int(.8*Hillary_length):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#corresponding training/testing target sets\n",
    "Clinton_y_train = [1 for x in Rand_Pos_Hillary[:int(.8*Hillary_length)]] + [0 for x in Rand_Neg_Hillary[:int(.8*Hillary_length)]]\n",
    "Clinton_y_test = [1 for x in Rand_Pos_Hillary[int(.8*Hillary_length):]] + [0 for x in Rand_Neg_Hillary[int(.8*Hillary_length):]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rand_Pos_Trump = [X.lower() for X in Pos_Trump_text.tolist()]\n",
    "random.shuffle(Rand_Pos_Trump)\n",
    "\n",
    "Rand_Neg_Trump = [X.lower() for X in Neg_Trump_text.tolist()]\n",
    "random.shuffle(Rand_Neg_Trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#80% training, 20% tesitng\n",
    "Trump_X_train = Rand_Pos_Trump[:int(.8*Trump_length)] + Rand_Neg_Trump[:int(.8*Trump_length)]\n",
    "Trump_X_test = Rand_Pos_Trump[int(.8*Trump_length):] + Rand_Neg_Trump[int(.8*Trump_length):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corresponding training/testing target sets\n",
    "Trump_y_train = [1 for x in Rand_Pos_Trump[:int(.8*Trump_length)]] + [0 for x in Rand_Neg_Trump[:int(.8*Trump_length)]]\n",
    "Trump_y_test = [1 for x in Rand_Pos_Trump[int(.8*Trump_length):]] + [0 for x in Rand_Neg_Trump[int(.8*Trump_length):]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training two text classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For single hashtag single subject tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count for feature appearence as opposed to total count due to small length of tweets\n",
    "C_vectorizer = CountVectorizer(ngram_range=(1,2), binary =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Clinton_training_features = C_vectorizer.fit_transform(Clinton_X_train)\n",
    "Clinton_testing_features = C_vectorizer.transform(Clinton_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count for feature appearence as opposed to total count due to small length of tweets\n",
    "T_vectorizer = CountVectorizer(ngram_range=(1,2), binary =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Trump_training_features = T_vectorizer.fit_transform(Trump_X_train)\n",
    "Trump_testing_features = T_vectorizer.transform(Trump_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validated grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters for logistic regression grid search\n",
    "logistic_param_grid = dict(C=np.logspace(np.log10(0.01) , np.log10(50000) , num=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Clinton_logistic_grid_search = GridSearchCV(LogisticRegression(), param_grid=logistic_param_grid,cv=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Clinton_logistic_grid_search.fit(Clinton_training_features, Clinton_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Clinton_logistic_classifier = Clinton_logistic_grid_search.best_estimator_\n",
    "print Clinton_logistic_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Clinton_logistic_classifier_predict_class = Clinton_logistic_classifier.predict(Clinton_testing_features)\n",
    "print 'Logistic Regression:'\n",
    "print accuracy_score(Clinton_logistic_classifier_predict_class,Clinton_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trump_logistic_grid_search = GridSearchCV(LogisticRegression(), param_grid=logistic_param_grid,cv=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Trump_logistic_grid_search.fit(Trump_training_features, Trump_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Trump_logistic_classifier = Trump_logistic_grid_search.best_estimator_\n",
    "print Trump_logistic_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Trump_logistic_classifier_predict_class = Trump_logistic_classifier.predict(Trump_testing_features)\n",
    "print 'Logistic Regression:'\n",
    "print accuracy_score(Trump_logistic_classifier_predict_class,Trump_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure accuracy on pos/neg components of each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pos_neg_acc(predict_class,y_test):\n",
    "    pos_correct_count = 0\n",
    "    neg_correct_count = 0\n",
    "    for i in xrange(len(y_test)):\n",
    "        if predict_class[i] != y_test[i]:\n",
    "            continue\n",
    "        else:\n",
    "            if y_test[i] == 1:\n",
    "                pos_correct_count = pos_correct_count + 1\n",
    "            else:\n",
    "                neg_correct_count = neg_correct_count + 1\n",
    "    return (float(pos_correct_count)/np.sum(y_test)),float(neg_correct_count)/(len(y_test)-np.sum(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pos_neg_acc(Clinton_logistic_classifier_predict_class,Clinton_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pos_neg_acc(Trump_logistic_classifier_predict_class,Trump_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Export classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('Clinton_logistic_classifier.pickle', 'wb')\n",
    "pickle.dump(Clinton_logistic_classifier, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('Clinton_vectorizer.pickle', 'wb')\n",
    "pickle.dump(C_vectorizer, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('Trump_logistic_classifier.pickle', 'wb')\n",
    "pickle.dump(Trump_logistic_classifier, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('Trump_vectorizer.pickle', 'wb')\n",
    "pickle.dump(T_vectorizer, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
